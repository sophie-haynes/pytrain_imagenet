{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c75ddb-0e70-4b6e-afe5-f8567b5d1de4",
   "metadata": {},
   "source": [
    "# Generating Class Feature Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4599dc61-c591-482e-8a30-7089590abdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision.models import resnet50\n",
    "import torchvision\n",
    "import random\n",
    "import pickle\n",
    "from torch.nn import Conv2d\n",
    "\n",
    "\n",
    "# set root dirs\n",
    "grey_dir = \"/home/local/data/sophie/imagenet/output/grey\"\n",
    "base_dir = \"/home/local/data/sophie/imagenet/output/base\"\n",
    "single_dir = \"/home/local/data/sophie/imagenet/output/single\"\n",
    "\n",
    "# grey_dir = \"/home/local/data/sophie/imagenet/output/grey/continued/\"\n",
    "# base_dir = \"/home/local/data/sophie/imagenet/output/base/continued/\"\n",
    "# configure GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# fetch imagenet classes \n",
    "with open('/home/local/data/sophie/imagenet/imagenet_classes.pkl', 'rb') as f:\n",
    "    clses = pickle.load(f)\n",
    "\n",
    "# define data augmentations\n",
    "img_size = 224\n",
    "transforms = torchvision.transforms.Compose([\n",
    "      torchvision.transforms.RandomCrop(img_size, padding=random.randint(0, 8)), # jitter\n",
    "      torchvision.transforms.RandomRotation((-45, 45)), # rotate\n",
    "      torchvision.transforms.RandomResizedCrop(img_size, scale=(0.9, 1.2), ratio=(1.0, 1.,0)) # scale\n",
    "    ])\n",
    "\n",
    "def convert_to_single_channel(model):\n",
    "    \"\"\"\n",
    "    Modifies the first convolutional layer of a given model to accept single-channel input.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to be modified.\n",
    "        \n",
    "    Returns:\n",
    "        torch.nn.Module: The modified model with a single-channel input.\n",
    "    \"\"\"\n",
    "    # Identify the first convolutional layer\n",
    "    conv1 = None\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, Conv2d):\n",
    "            conv1 = layer\n",
    "            conv1_name = name\n",
    "            break\n",
    "    \n",
    "    if conv1 is None:\n",
    "        raise ValueError(\"The model does not have a Conv2D layer.\")\n",
    "    \n",
    "    # Create a new convolutional layer with the same parameters except for the input channels\n",
    "    new_conv1 = Conv2d(\n",
    "        in_channels=1,  # Change input channels to 1\n",
    "        out_channels=conv1.out_channels,\n",
    "        kernel_size=conv1.kernel_size,\n",
    "        stride=conv1.stride,\n",
    "        padding=conv1.padding,\n",
    "        bias=conv1.bias is not None\n",
    "    )\n",
    "    \n",
    "    # Replace the old conv1 layer with the new one\n",
    "    def recursive_setattr(model, attr, value):\n",
    "        attr_list = attr.split('.')\n",
    "        for attr_name in attr_list[:-1]:\n",
    "            model = getattr(model, attr_name)\n",
    "        setattr(model, attr_list[-1], value)\n",
    "    \n",
    "    recursive_setattr(model, conv1_name, new_conv1)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_models(base_model_path,grey_model_path):\n",
    "    # initalize models\n",
    "    base_model = resnet50(pretrained=True)\n",
    "    grey_model = resnet50(pretrained=True)\n",
    "\n",
    "    # load weights\n",
    "    base_weights = torch.load(base_model_path, map_location='cpu')\n",
    "    # configure state dict\n",
    "    new_state_dict = {}\n",
    "    for k, v in base_weights['model'].items():\n",
    "        k = k.replace(\"module.\", \"\")\n",
    "        new_state_dict[k] = v\n",
    "    # load model with state dict\n",
    "    base_model.load_state_dict(new_state_dict)\n",
    "    # disable grad\n",
    "    for param in base_model.parameters():\n",
    "      param.requires_grad_(False)\n",
    "    \n",
    "    # load weights\n",
    "    grey_weights = torch.load(grey_model_path, map_location='cpu')\n",
    "    # configure state dict\n",
    "    new_state_dict = {}\n",
    "    for k, v in grey_weights['model'].items():\n",
    "        k = k.replace(\"module.\", \"\")\n",
    "        new_state_dict[k] = v\n",
    "    # load model with state dict\n",
    "    grey_model.load_state_dict(new_state_dict)\n",
    "    # disable grad\n",
    "    for param in grey_model.parameters():\n",
    "      param.requires_grad_(False)\n",
    "\n",
    "    # send to GPU\n",
    "    base_model.to(device)\n",
    "    grey_model.to(device)\n",
    "    # set as eval \n",
    "    base_model.eval()\n",
    "    grey_model.eval()\n",
    "    return base_model, grey_model\n",
    "\n",
    "def load_models_3(base_model_path,grey_model_path, single_model_path):\n",
    "    # initalize models\n",
    "    base_model = resnet50(pretrained=True)\n",
    "    grey_model = resnet50(pretrained=True)\n",
    "    single_model = resnet50(pretrained=True)\n",
    "\n",
    "    # load weights\n",
    "    base_weights = torch.load(base_model_path, map_location='cpu')\n",
    "    # configure state dict\n",
    "    new_state_dict = {}\n",
    "    for k, v in base_weights['model'].items():\n",
    "        k = k.replace(\"module.\", \"\")\n",
    "        new_state_dict[k] = v\n",
    "    # load model with state dict\n",
    "    base_model.load_state_dict(new_state_dict)\n",
    "    # disable grad\n",
    "    for param in base_model.parameters():\n",
    "      param.requires_grad_(False)\n",
    "    \n",
    "    # load weights\n",
    "    grey_weights = torch.load(grey_model_path, map_location='cpu')\n",
    "    # configure state dict\n",
    "    new_state_dict = {}\n",
    "    for k, v in grey_weights['model'].items():\n",
    "        k = k.replace(\"module.\", \"\")\n",
    "        new_state_dict[k] = v\n",
    "    # load model with state dict\n",
    "    grey_model.load_state_dict(new_state_dict)\n",
    "    # disable grad\n",
    "    for param in grey_model.parameters():\n",
    "      param.requires_grad_(False)\n",
    "        \n",
    "    single_model = convert_to_single_channel(single_model)\n",
    "     # load weights\n",
    "    single_weights = torch.load(single_model_path, map_location='cpu')\n",
    "    # configure state dict\n",
    "    new_state_dict = {}\n",
    "    for k, v in single_weights['model'].items():\n",
    "        k = k.replace(\"module.\", \"\")\n",
    "        new_state_dict[k] = v\n",
    "    # load model with state dict\n",
    "    single_model.load_state_dict(new_state_dict)\n",
    "    # disable grad\n",
    "    for param in single_model.parameters():\n",
    "      param.requires_grad_(False)\n",
    "\n",
    "    # send to GPU\n",
    "    base_model.to(device)\n",
    "    grey_model.to(device)\n",
    "    single_model.to(device)\n",
    "    # set as eval\n",
    "    base_model.eval()\n",
    "    grey_model.eval()\n",
    "    single_model.eval()\n",
    "    return base_model, grey_model, single_model\n",
    "    \n",
    "def visualize_neuron(model, layer, neuron_indices, img_shape=(3, 224, 224), iterations=30, lr=0.1, device='\"cuda:0\"', transforms=None):#, device='cuda', transforms=None):\n",
    "    # Initialize the input image with requires_grad=True\n",
    "    input_img = torch.randn(1, *img_shape, requires_grad=True, device=device)\n",
    "    # input_img = torch.randn(1, *img_shape, requires_grad=True, device='cpu')\n",
    "    optimizer = torch.optim.Adam([input_img], lr=lr)\n",
    "\n",
    "    activations = None\n",
    "\n",
    "    # Non-intrusive hook function that captures activations\n",
    "    def non_intrusive_hook_fn(module, input, output):\n",
    "        nonlocal activations\n",
    "        activations = output  # Do not detach to keep the graph intact\n",
    "\n",
    "    # Register the hook to capture the layer's output\n",
    "    hook = layer.register_forward_hook(non_intrusive_hook_fn)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if transforms is not None:\n",
    "            trs_img = transforms(input_img)\n",
    "        else:\n",
    "            trs_img = input_img\n",
    "\n",
    "        # Forward pass\n",
    "        model(trs_img)\n",
    "\n",
    "        # Ensure that neuron_indices is within bounds\n",
    "        if neuron_indices >= activations.shape[1]:\n",
    "            raise ValueError(f\"neuron_indices {neuron_indices} is out of bounds for activations with shape {activations.shape}\")\n",
    "\n",
    "        # Loss calculation as in Method 2\n",
    "        if activations.dim() == 2:\n",
    "            channel_activations = activations[:, neuron_indices]\n",
    "        else:\n",
    "            channel_activations = activations[:, neuron_indices, :, :]\n",
    "\n",
    "        loss = -channel_activations.mean()\n",
    "\n",
    "        # Backward pass to calculate gradients\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Remove the hook\n",
    "    hook.remove()\n",
    "\n",
    "    return input_img.detach()\n",
    "\n",
    "def generateClassImages(base_model, grey_model, neuron, its=3000, lr=0.05, layer_name='fc', seed=0,trs=transforms, device=\"cuda:0\"):\n",
    "    # get the target layers\n",
    "    colour_layer1 = dict([*base_model.named_modules()])[layer_name]\n",
    "    grey_layer1 = dict([*grey_model.named_modules()])[layer_name]\n",
    "    # generate images\n",
    "    colour_mean_img1 = visualize_neuron(base_model, colour_layer1, neuron, iterations=its, \n",
    "                                        lr=lr, transforms=trs, device=device)\n",
    "    grey_mean_img1 = visualize_neuron(grey_model, grey_layer1, neuron, iterations=its, \n",
    "                                      lr=lr, transforms=trs, device=device)\n",
    "    # normalise images\n",
    "    colour_mean_img1_norm = (colour_mean_img1.cpu().numpy()-colour_mean_img1.cpu().numpy().min())/(colour_mean_img1.cpu().numpy().max()-colour_mean_img1.cpu().numpy().min())\n",
    "    grey_mean_img1_norm = (grey_mean_img1.cpu().numpy()-grey_mean_img1.cpu().numpy().min())/(grey_mean_img1.cpu().numpy().max()-grey_mean_img1.cpu().numpy().min())\n",
    "    \n",
    "    return colour_mean_img1, colour_mean_img1_norm, grey_mean_img1, grey_mean_img1_norm\n",
    "\n",
    "def generateClassImages_3(base_model, grey_model, single_model, neuron, its=3000, lr=0.05, layer_name='fc', seed=0,trs=transforms, device=\"cuda:0\"):\n",
    "    # get the target layers\n",
    "    colour_layer1 = dict([*base_model.named_modules()])[layer_name]\n",
    "    grey_layer1 = dict([*grey_model.named_modules()])[layer_name]\n",
    "    single_layer1 = dict([*single_model.named_modules()])[layer_name]\n",
    "    # generate images\n",
    "    colour_mean_img1 = visualize_neuron(base_model, colour_layer1, neuron, iterations=its, \n",
    "                                        lr=lr, transforms=trs, device=device)\n",
    "    grey_mean_img1 = visualize_neuron(grey_model, grey_layer1, neuron, iterations=its, \n",
    "                                      lr=lr, transforms=trs, device=device)\n",
    "    single_mean_img1 = visualize_neuron(single_model, single_layer1, neuron, img_shape=(1, 224, 224),iterations=its, \n",
    "                                      lr=lr, transforms=trs, device=device)\n",
    "    # normalise images\n",
    "    colour_mean_img1_norm = (colour_mean_img1.cpu().numpy()-colour_mean_img1.cpu().numpy().min())/(colour_mean_img1.cpu().numpy().max()-colour_mean_img1.cpu().numpy().min())\n",
    "    grey_mean_img1_norm = (grey_mean_img1.cpu().numpy()-grey_mean_img1.cpu().numpy().min())/(grey_mean_img1.cpu().numpy().max()-grey_mean_img1.cpu().numpy().min())\n",
    "    single_mean_img1_norm = (single_mean_img1.cpu().numpy()-single_mean_img1.cpu().numpy().min())/(single_mean_img1.cpu().numpy().max()-single_mean_img1.cpu().numpy().min())\n",
    "    \n",
    "    return colour_mean_img1, colour_mean_img1_norm, grey_mean_img1, grey_mean_img1_norm, single_mean_img1, single_mean_img1_norm\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d61d47-65f3-4b8e-b63e-45a8edb3166c",
   "metadata": {},
   "source": [
    "#### Pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d65e86-d4f3-44ec-a9f8-70c7c0ed3c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 89.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "neuron = 963 #pizza\n",
    "img_class = clses[neuron].split(\",\")[0]\n",
    "plt_dir = \"/home/local/data/sophie/imagenet/output/viz_plots/{}\".format(img_class)\n",
    "if not os.path.exists(plt_dir):\n",
    "    os.makedirs(plt_dir)\n",
    "\n",
    "# iterate over models\n",
    "for model in os.listdir(grey_dir):\n",
    "    if \"model\" in model:\n",
    "        # set current model paths\n",
    "        grey_model_path = os.path.join(grey_dir, model)\n",
    "        base_model_path = os.path.join(base_dir, model.replace(\"grey\", \"base\"))\n",
    "        # load models\n",
    "        base_model, grey_model = load_models(base_model_path,grey_model_path)\n",
    "        \n",
    "        colour_image, norm_colour_image, grey_image, norm_grey_image, = generateClassImages(base_model, grey_model, neuron)\n",
    "        \n",
    "        # generate plot\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(norm_colour_image[0].transpose(1,2,0))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Colour FC: {}\".format(img_class))\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(norm_grey_image[0].transpose(1,2,0))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Grey FC: {}\".format(img_class))\n",
    "        plt.savefig(os.path.join(plt_dir, \"{}.png\".format(model.split(\"_\")[-1].split(\".\")[0])), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d5760-2919-4bb3-98b4-895c7ec3558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = 963 #pizza\n",
    "img_class = clses[neuron].split(\",\")[0]\n",
    "plt_dir = \"/home/local/data/sophie/imagenet/output/viz_plots/single/{}\".format(img_class)\n",
    "if not os.path.exists(plt_dir):\n",
    "    os.makedirs(plt_dir)\n",
    "\n",
    "# iterate over models\n",
    "for model in os.listdir(single_dir):\n",
    "    if \"model\" in model:\n",
    "        # set current model paths\n",
    "        single_model_path = os.path.join(single_dir, model)\n",
    "        base_model_path = os.path.join(base_dir, model.replace(\"single\", \"base\"))\n",
    "        grey_model_path = os.path.join(grey_dir, model.replace(\"single\", \"grey\"))\n",
    "        # load models\n",
    "        base_model, grey_model, single_model = load_models_3(base_model_path,grey_model_path, single_model_path)\n",
    "        \n",
    "        colour_image, norm_colour_image, grey_image, norm_grey_image, single_image, norm_single_image, = generateClassImages_3(base_model, grey_model, single_model, neuron, its=3000)\n",
    "        \n",
    "        # generate plot\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(norm_colour_image[0].transpose(1,2,0))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Colour FC: {}\".format(img_class))\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(norm_grey_image[0].transpose(1,2,0))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Grey FC: {}\".format(img_class))\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(norm_single_image[0].transpose(1,2,0), cmap=\"binary\")\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Single FC: {}\".format(img_class))\n",
    "        plt.savefig(os.path.join(plt_dir, \"{}.png\".format(model.split(\"_\")[-1].split(\".\")[0])), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b014bc19-d455-4fc9-8371-bb16534aa440",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908c8ec-6d42-4751-a33a-f94877366397",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = 388\n",
    "img_class = clses[neuron].split(\",\")[0]\n",
    "plt_dir = \"/home/local/data/sophie/imagenet/output/viz_plots/{}\".format(img_class)\n",
    "if not os.path.exists(plt_dir):\n",
    "    os.makedirs(plt_dir)\n",
    "\n",
    "# iterate over models\n",
    "for model in os.listdir(grey_dir):\n",
    "    if \"model\" in model:\n",
    "        # set current model paths\n",
    "        grey_model_path = os.path.join(grey_dir, model)\n",
    "        base_model_path = os.path.join(base_dir, model.replace(\"grey\", \"base\"))\n",
    "        # load models\n",
    "        base_model, grey_model = load_models(base_model_path,grey_model_path)\n",
    "        \n",
    "        colour_image, norm_colour_image, grey_image, norm_grey_image, = generateClassImages(base_model, grey_model, neuron)\n",
    "        \n",
    "        # generate plot\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(norm_colour_image[0].transpose(1,2,0))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Colour FC: {}\".format(img_class))\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(norm_grey_image[0].transpose(1,2,0))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Grey FC: {}\".format(img_class))\n",
    "        plt.savefig(os.path.join(plt_dir, \"{}.png\".format(model.split(\"_\")[-1].split(\".\")[0])), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63acfad-a980-42dd-b37e-47d64d558680",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8da45-776d-4171-bcac-7ed94ac7375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = 470\n",
    "img_class = clses[neuron].split(\",\")[0]\n",
    "plt_dir = \"/home/local/data/sophie/imagenet/output/viz_plots/{}\".format(img_class)\n",
    "if not os.path.exists(plt_dir):\n",
    "    os.makedirs(plt_dir)\n",
    "\n",
    "# iterate over models\n",
    "for model in os.listdir(grey_dir):\n",
    "    if \"model\" in model:\n",
    "        # set current model paths\n",
    "        grey_model_path = os.path.join(grey_dir, model)\n",
    "        base_model_path = os.path.join(base_dir, model.replace(\"grey\", \"base\"))\n",
    "        # load models\n",
    "        base_model, grey_model = load_models(base_model_path,grey_model_path)\n",
    "        \n",
    "        colour_image, norm_colour_image, grey_image, norm_grey_image, = generateClassImages(base_model, grey_model, neuron)\n",
    "        \n",
    "        # generate plot\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(norm_colour_image[0].transpose(1,2,0))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Colour FC: {}\".format(img_class))\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(norm_grey_image[0].transpose(1,2,0))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Grey FC: {}\".format(img_class))\n",
    "        plt.savefig(os.path.join(plt_dir, \"{}.png\".format(model.split(\"_\")[-1].split(\".\")[0])), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda64f01-4472-442a-9323-471331af0c12",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44665f48-ace4-4d5b-bb4e-cf42ba35194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = 8\n",
    "img_class = clses[neuron].split(\",\")[0]\n",
    "plt_dir = \"/home/local/data/sophie/imagenet/output/viz_plots/{}\".format(img_class)\n",
    "if not os.path.exists(plt_dir):\n",
    "    os.makedirs(plt_dir)\n",
    "\n",
    "# iterate over models\n",
    "for model in os.listdir(grey_dir):\n",
    "    # set current model paths\n",
    "    grey_model_path = os.path.join(grey_dir, model)\n",
    "    base_model_path = os.path.join(base_dir, model.replace(\"grey\", \"base\"))\n",
    "    # load models\n",
    "    base_model, grey_model = load_models(base_model_path,grey_model_path)\n",
    "    \n",
    "    colour_image, norm_colour_image, grey_image, norm_grey_image, = generateClassImages(base_model, grey_model, neuron)\n",
    "    \n",
    "    # generate plot\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(norm_colour_image[0].transpose(1,2,0))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Colour FC: {}\".format(img_class))\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(norm_grey_image[0].transpose(1,2,0))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Grey FC: {}\".format(img_class))\n",
    "    plt.savefig(os.path.join(plt_dir, \"{}.png\".format(model.split(\"_\")[-1].split(\".\")[0])), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a7c331-7f27-40c5-842e-71eeac78daaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
